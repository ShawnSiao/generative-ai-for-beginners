[![开源大模型](../../img/18-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# 微调你的大语言模型 (LLM)

使用大型语言模型来构建生成型 AI 应用程序会带来一些新挑战。一个关键问题是确保模型生成的内容对特定用户请求的响应质量（准确性和相关性）。在之前的课程中，我们讨论了如提示工程和检索增强生成等技术，这些方法试图通过_修改输入提示_来解决这个问题。

在今天的课程中，我们讨论第三种技术——**微调**，它通过_重新训练模型本身_并使用额外的数据来解决这个挑战。让我们深入了解细节。

## 学习目标

本课程介绍了针对预训练语言模型的微调概念，探讨了这种方法的好处与挑战，并提供了在何时以及如何使用微调来提高生成 AI 模型性能的指导。

通过本课程的学习，你应该能够回答以下问题：

- 什么是语言模型的微调？
- 微调何时有用，为什么有用？
- 我该如何微调一个预训练模型？
- 微调的局限性是什么？

准备好了吗？让我们开始吧。

## 插图指南

想要在深入了解之前先对本课程的内容有个大概的了解吗？请查看这份插图指南，它描述了我们本课程的学习过程——从理解微调的核心概念和动机，到理解微调任务的过程和最佳实践。这是一个值得深入探讨的有趣主题，别忘了查看[资源页面](./RESOURCES.md?WT.mc_id=academic-105485-koreyst)，获取更多支持你自学旅程的链接！

![微调语言模型插图指南](../../img/18-fine-tuning-sketchnote.png?WT.mc_id=academic-105485-koreyst)

## 什么是语言模型的微调？

根据定义，大型语言模型是_预训练的_，使用来自各种来源的大量文本数据进行训练，包括互联网。正如我们在之前的课程中学到的，我们需要像_提示工程_和_检索增强生成_这样的技术，来提高模型对用户问题（“提示”）的响应质量。

一种常见的提示工程技术是通过提供_指令_（明确的指导）或_给出几个示例_（隐式的指导）来给模型更多的反馈，告诉它应该如何回应。这种方法被称为_少量学习（few-shot learning）_，但它有两个限制：

- 模型的令牌限制可能限制你能给出的示例数量，从而限制了效果。
- 模型的令牌成本可能使得在每个提示中都加入示例变得昂贵，从而限制了灵活性。

微调是机器学习系统中的一种常见做法，我们通过使用新的数据来对预训练的模型进行再训练，从而提高其在特定任务上的表现。在语言模型的上下文中，我们可以用一组精心挑选的示例来对预训练的模型进行微调，针对特定任务或应用领域创建一个**定制模型**，使其在该特定任务或领域上表现得更加准确和相关。微调的一个附带好处是，它还可以减少少量学习所需的示例数量——从而减少令牌的使用和相关的成本。

## 何时以及为什么应该进行微调？

在_这个_上下文中，当我们谈论微调时，我们指的是**监督式**微调，其中通过**添加新的数据**（这些数据不包含在原始训练数据集中）来进行再训练。这不同于无监督微调方法，在无监督微调中，模型是在原始数据上进行再训练，但使用不同的超参数。

需要记住的关键点是，微调是一种高级技术，需要一定的专业知识才能获得预期的效果。如果操作不当，可能无法提供预期的改进，甚至可能降低模型在特定领域的表现。

因此，在你学习“如何”微调语言模型之前，首先需要了解“为什么”你应该选择这种方法，以及“何时”开始微调过程。可以从问自己以下问题开始：

- **使用场景**：你进行微调的_使用场景_是什么？你希望改善当前预训练模型的哪一方面？
- **替代方案**：你是否尝试过_其他技术_来实现预期的结果？可以将它们作为对比基准。
  - 提示工程：尝试使用少量提示，结合相关的提示响应示例，评估响应质量。
  - 检索增强生成：尝试通过检索你的数据并将查询结果加入提示来增强模型，评估响应质量。
- **成本**：你是否识别了进行微调的成本？
  - 可调性 - 预训练模型是否可以进行微调？
  - 努力 - 准备训练数据、评估和优化模型的工作量。
  - 计算 - 运行微调作业以及部署微调模型的计算资源。
  - 数据 - 获取足够质量的示例数据，以便微调产生有效影响。
- **收益**：你是否确认了微调的收益？
  - 质量 - 微调后的模型是否优于基准模型？
  - 成本 - 是否通过简化提示来减少了令牌的使用？
  - 可扩展性 - 是否可以将基础模型重新用于新的领域？

通过回答这些问题，你应该能够判断微调是否是适合你的使用场景的正确方法。理想情况下，只有当收益超过成本时，微调才是有效的。一旦决定继续，接下来就是思考_如何_微调预训练模型。

想要更深入了解决策过程吗？观看[是否微调](https://www.youtube.com/watch?v=0Jo-z-MFxJs)。

## 我们如何微调预训练模型？

要对预训练模型进行微调，你需要准备以下内容：

- 一个可微调的预训练模型
- 用于微调的数据集
- 一个训练环境来运行微调任务
- 一个托管环境来部署微调后的模型

## 微调实战

以下资源提供了逐步的教程，帮助你通过选定的模型和精心挑选的数据集来进行实际操作。要跟随这些教程，你需要在特定提供商处拥有账户，并且可以访问相关的模型和数据集。

| 提供商       | 教程链接                                                                                                                                                                    | 描述                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ---------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| OpenAI       | [如何微调聊天模型](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)      | 学习如何微调 `gpt-35-turbo` 用于特定领域（“食谱助手”），包括准备训练数据、运行微调任务，并使用微调后的模型进行推理。                                                                                                                                                                                                                                             |
| Azure OpenAI | [GPT 3.5 Turbo 微调教程](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | 学习如何在 Azure 上微调 `gpt-35-turbo-0613` 模型，涵盖创建并上传训练数据、运行微调任务、部署并使用新模型的步骤。                                                                                                                                                                                                                                              |
| Hugging Face | [用 Hugging Face 微调 LLM](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                          | 本博客文章指导你使用 Hugging Face 的 [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) 库和 [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) 对一个开源 LLM（例如 `CodeLlama 7B`）进行微调。                                                                                                                                 |
| 🤗 AutoTrain | [使用 AutoTrain 微调 LLM](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                    | AutoTrain（或 AutoTrain Advanced）是 Hugging Face 开发的一个 Python 库，允许进行多种任务的微调，包括 LLM 微调。AutoTrain 是一种无代码解决方案，可以在你的云端、Hugging Face Spaces 或本地进行微调。它支持 Web GUI、CLI 和通过 YAML 配置文件进行训练。                                                                                                           |

## 作业

选择上面的一个教程并跟随操作。_我们可能会在本仓库中的 Jupyter Notebooks 中复制这些教程的版本，供参考。请直接使用原始源来获取最新版本_。

## 做得好！继续学习。

完成本课程后，请查看我们的[生成 AI 学习合集](https://aka.ms/genai-collection?WT
